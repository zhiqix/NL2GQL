{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1eb41b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt/few.jsonl completed\n",
      "gpt/few_code_skel.jsonl completed\n",
      "gpt/few_code.jsonl completed\n",
      "davinci/zero.jsonl completed\n",
      "davinci/few.jsonl completed\n",
      "gpt4/zero_code_skel.jsonl completed\n",
      "gpt4/zero_final.jsonl completed\n",
      "gpt4/few.jsonl completed\n",
      "gpt4/few_code.jsonl completed\n"
     ]
    }
   ],
   "source": [
    "# Check json format errors\n",
    "import json\n",
    "import os\n",
    "\n",
    "foler_list = ['gpt','davinci','gpt4']\n",
    "\n",
    "for folder_path in foler_list:\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    def process_json_file(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as input_file:\n",
    "            line_number = 0\n",
    "            for line in input_file:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"{file_path}, line {line_number + 1}: JSON error\")\n",
    "                line_number += 1\n",
    "\n",
    "    for file in files:\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        process_json_file(full_path)\n",
    "        print(f\"{full_path} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0783f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-31 16:00:23,458]:Get connection to ('127.0.0.1', 9669)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/gpt/output_few.jsonl success\n",
      "output/gpt/output_few_code_skel.jsonl success\n",
      "output/gpt/output_few_code.jsonl success\n",
      "output/davinci/output_zero.jsonl success\n",
      "output/davinci/output_few.jsonl success\n",
      "output/gpt4/output_zero_code_skel.jsonl success\n",
      "output/gpt4/output_zero_final.jsonl success\n",
      "output/gpt4/output_few.jsonl success\n",
      "output/gpt4/output_few_code.jsonl success\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import os\n",
    "\n",
    "from nebula2.gclient.net import ConnectionPool\n",
    "from nebula2.Config import Config\n",
    "# from nebula2.data.ResultSet import ResultSe\n",
    "# config\n",
    "config = Config()\n",
    "config.max_connection_pool_size = 10\n",
    "# connect\n",
    "connection_pool = ConnectionPool()\n",
    "ok = connection_pool.init([('127.0.0.1', 9669)], config)\n",
    "session = connection_pool.get_session('root', 'nebula')\n",
    "\n",
    "foler_list = ['gpt','davinci','gpt4']\n",
    "\n",
    "def prosess_db_test(graph_name,data):\n",
    "    for line in data:\n",
    "        use_graph = f'USE {graph_name}'\n",
    "        session.execute(use_graph)\n",
    "        content = line.get('gpt')\n",
    "        result = line.get('result')\n",
    "        gpt_result_list = []\n",
    "        gpt_result = session.execute(content)\n",
    "        if gpt_result.is_succeeded() == False:\n",
    "            line['error'] = [\"语法错误\"]\n",
    "        else:\n",
    "            n = gpt_result.row_size()\n",
    "            for i in range(n):\n",
    "                gpt_result_list.append(str(gpt_result.row_values(i)))\n",
    "            if len(gpt_result_list) == 0 and len(result) != 0:\n",
    "                line['error'] = [\"语法错误\"]\n",
    "            elif len(gpt_result_list) != 0 and gpt_result_list[0] == \"[__NULL__]\" and len(result) != 0:\n",
    "                line['error'] = [\"语法错误\"]\n",
    "        line['gpt_result'] = gpt_result_list\n",
    "        output_result.append(line)\n",
    "\n",
    "for folder_path in foler_list:\n",
    "\n",
    "    output_path = 'output/' + folder_path\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        output_file = \"output_\" + file\n",
    "        output_full_path = os.path.join(output_path, output_file)\n",
    "\n",
    "        class_disease = []\n",
    "        class_potter = []\n",
    "        class_nba = []\n",
    "        output_result = []\n",
    "\n",
    "        with open(full_path, 'r') as input_file, open(output_full_path, 'w') as output_file:  \n",
    "            for line in input_file:  \n",
    "                data = json.loads(line)\n",
    "                if data.get('class') == \"disease\":\n",
    "                    class_disease.append(data)\n",
    "                elif data.get('class') == \"potter\":\n",
    "                    class_potter.append(data)\n",
    "                elif data.get('class') == \"nba\":\n",
    "                    class_nba.append(data)\n",
    "\n",
    "            prosess_db_test('disease', class_disease)\n",
    "            prosess_db_test('harrypotter_new', class_potter)\n",
    "            prosess_db_test('nba', class_nba)\n",
    "\n",
    "            json.dump(output_result, output_file, ensure_ascii=False, indent=4)\n",
    "        print(output_full_path+\" success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce77a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
